# main.py - ä¸»å‡½æ•°éƒ¨åˆ†

from langchain.agents import AgentType, initialize_agent
from langchain.memory import ConversationBufferMemory
from langchain_openai.chat_models import ChatOpenAI
import os
import json
import sys

# å¯¼å…¥æ‚¨çš„å·¥å…·æ¨¡å—ï¼ˆç¡®ä¿è¿™äº›æ–‡ä»¶å­˜åœ¨äºç›¸åŒç›®å½•æˆ–å·²æ·»åŠ åˆ°è·¯å¾„ä¸­ï¼‰
from retriever_tool import create_history_aware_retriever_tool
from linkedin_job_tool import LinkedInJobTool
from web_search_tool import create_web_search_tool, WebSearchTool

# å¯¼å…¥ç”¨æˆ·ç”»åƒç›¸å…³æ¨¡å—
from user_profile_collector import get_user_profile_collection_llm, interactive_user_profile_collection
from user_template import select_template_for_user

def get_chat_llm(streaming=True):
    """åˆå§‹åŒ–èŠå¤©è¯­è¨€æ¨¡å‹"""
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",  # æˆ– "gpt-4"
        temperature=0.3,
        max_tokens=512,
        timeout=None,
        max_retries=2,
        streaming=streaming,
        openai_api_key=os.environ.get("OPENAI_API_KEY")
    )
    return llm

def save_conversation_to_history(memory, conversation_history):
    """å°†å¯¹è¯å†å²ä¿å­˜åˆ°ä¼šè¯å­˜å‚¨"""
    for message in conversation_history:
        if message["role"] == "assistant":
            memory.chat_memory.add_ai_message(message["content"])
        elif message["role"] == "user":
            memory.chat_memory.add_user_message(message["content"])

def main():
   
    # è®¾ç½®ä¼šè¯ID
    session_id = "user123"
    
    # åˆå§‹åŒ–LLM
    llm = get_chat_llm()
    get_user_profile_llm = get_user_profile_collection_llm()

    # åˆ›å»ºå·¥å…·å®ä¾‹
    # 1. å†å²æ„ŸçŸ¥æ£€ç´¢å·¥å…·
    pdf_path = 'knowledge_database/ED520114.pdf'  # ç¡®ä¿æ­¤è·¯å¾„æŒ‡å‘æ‚¨çš„PDFæ–‡ä»¶ 9900\knowledge_database
    print(os.path.exists(pdf_path))
    retriever_tool = create_history_aware_retriever_tool(llm, pdf_path)
    
    # 2. LinkedInèŒä½æœç´¢å·¥å…·
    linkedin_tool = LinkedInJobTool()

    # 3. Webæœç´¢å·¥å…·
    web_search_tool = create_web_search_tool()
    
    # æ”¶é›†ç”¨æˆ·ç”»åƒ
    user_profile, history, corrections= interactive_user_profile_collection(get_user_profile_llm)
    
    # é€‰æ‹©æ¨¡æ¿
    selected_template = select_template_for_user(user_profile)

    # æå–é£æ ¼æŒ‡å—å’Œå·¥å…·ä½¿ç”¨æŒ‡å—
    style_guide = selected_template.get('style_guide', '')
    tool_usage_guidelines = selected_template.get('Tool_Usage_Guidelines', '')
    
    
    # åˆ›å»ºåŒ…å«ç”¨æˆ·ä¿¡æ¯çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤º
    custom_prefix = f"""You are a professor specializing in clean energy careers guidance.

    USER PROFILE:
    - Age: {user_profile['age']}
    - Education_level: {user_profile['education_background']}
    - Occupation_status: {selected_template['name']}
    - Clean Energy Working Experience: {user_profile['working_experience']}


    - Carefully consider the user's background information(USER PROFILE) above when crafting your responses. Tailor your advice, explanations, and tool selections to be most relevant and helpful given their specific age, education level, occupation status, and experience in the clean energy sector.
    
    - When responding to the user, carefully incorporate the principles and communication style from the following STYLE GUIDE:
    {style_guide}
    
    - For determining when and how to use available tools, follow these TOOL USAGE GUIDELINES:
    {tool_usage_guidelines}
    
    - Ensure your responses maintain the professional tone, expertise level, and structured approach outlined in the style guide while leveraging tools according to the specified guidelines.
    """

    
    # å°†å·¥å…·ç»„åˆæˆå·¥å…·åˆ—è¡¨
    tools = [
        retriever_tool,  # å‡è®¾è¿™å·²ç»æ˜¯LangChain Toolç±»å‹
        linkedin_tool.get_tool(),
        web_search_tool

    ]
    
    # è®¾ç½®ä¼šè¯è®°å¿†
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    
    # ä¿å­˜åˆå§‹å¯¹è¯å†å²
    save_conversation_to_history(memory, history)
    

    # è‡ªå®šä¹‰åç¼€
    suffix = """Begin!

    Previous conversation history:
    {chat_history}

    New human input: {input}
    {agent_scratchpad}"""

    # é…ç½®Agent
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
        verbose=True,  # è®¾ä¸ºTrueå¯ä»¥çœ‹åˆ°è¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹
        memory=memory,
        handle_parsing_errors=True,
        agent_kwargs={
            "prefix": custom_prefix,
            #"format_instructions": format_instructions,
            "suffix": suffix,
            "ai_prefix": "CleanEnergyExpert"
        }
    )
    
    # æ·»åŠ æ¬¢è¿æ¶ˆæ¯
    welcome_message = (
        f"Thank you for sharing your information! "
        f"I'll tailor my guidance to your needs. How can I help with your clean energy career questions today? ğŸ˜Š"
        
    )
    print(f"ğŸ’¬ Chatbot:{welcome_message}")
    
    # å¯¹è¯å¾ªç¯
    while True:
        user_input = input("ğŸ§‘â€ğŸ’» You:")
        if user_input.lower() == "exit" or user_input.lower() == "end":
            print("ğŸ’¬ Chatbot:Thank you for our conversation. Best of luck with your clean energy career journey!")
            break
        
        # ä½¿ç”¨Agentå¤„ç†ç”¨æˆ·è¾“å…¥
        try:
            response = agent.run(user_input)
            print(f"ğŸ’¬ Chatbot:{response}")
        except Exception as e:
            print(f"Error: {str(e)}")
            print("ğŸ’¬ Chatbot:I apologize for the error. How else can I assist you?")

if __name__ == "__main__":
    main()